{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import yfinance as yf\n",
    "from dataset import SlidingWindowTransformer\n",
    "from models.lstm import LSTMForecaster\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from training_arguments import TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>12.87</td>\n",
       "      <td>12.80</td>\n",
       "      <td>12.90</td>\n",
       "      <td>12.66</td>\n",
       "      <td>12.87</td>\n",
       "      <td>65420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>12.92</td>\n",
       "      <td>12.86</td>\n",
       "      <td>13.04</td>\n",
       "      <td>12.82</td>\n",
       "      <td>12.92</td>\n",
       "      <td>55018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>12.96</td>\n",
       "      <td>12.88</td>\n",
       "      <td>12.99</td>\n",
       "      <td>12.83</td>\n",
       "      <td>12.96</td>\n",
       "      <td>37484000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-07</th>\n",
       "      <td>13.42</td>\n",
       "      <td>13.15</td>\n",
       "      <td>13.49</td>\n",
       "      <td>13.13</td>\n",
       "      <td>13.42</td>\n",
       "      <td>98200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08</th>\n",
       "      <td>13.32</td>\n",
       "      <td>13.35</td>\n",
       "      <td>13.45</td>\n",
       "      <td>13.18</td>\n",
       "      <td>13.32</td>\n",
       "      <td>60214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>89.65</td>\n",
       "      <td>89.41</td>\n",
       "      <td>89.65</td>\n",
       "      <td>89.23</td>\n",
       "      <td>89.65</td>\n",
       "      <td>42728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>89.46</td>\n",
       "      <td>89.69</td>\n",
       "      <td>89.78</td>\n",
       "      <td>89.38</td>\n",
       "      <td>89.46</td>\n",
       "      <td>17626000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>93.44</td>\n",
       "      <td>90.05</td>\n",
       "      <td>93.52</td>\n",
       "      <td>89.97</td>\n",
       "      <td>93.44</td>\n",
       "      <td>120108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>93.49</td>\n",
       "      <td>94.15</td>\n",
       "      <td>95.07</td>\n",
       "      <td>93.30</td>\n",
       "      <td>93.49</td>\n",
       "      <td>123732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>92.34</td>\n",
       "      <td>93.70</td>\n",
       "      <td>94.20</td>\n",
       "      <td>92.03</td>\n",
       "      <td>92.34</td>\n",
       "      <td>73494000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1761 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Close   Open   High    Low  Close     Volume\n",
       "Date                                                        \n",
       "2013-01-02      12.87  12.80  12.90  12.66  12.87   65420000\n",
       "2013-01-03      12.92  12.86  13.04  12.82  12.92   55018000\n",
       "2013-01-04      12.96  12.88  12.99  12.83  12.96   37484000\n",
       "2013-01-07      13.42  13.15  13.49  13.13  13.42   98200000\n",
       "2013-01-08      13.32  13.35  13.45  13.18  13.32   60214000\n",
       "...               ...    ...    ...    ...    ...        ...\n",
       "2019-12-23      89.65  89.41  89.65  89.23  89.65   42728000\n",
       "2019-12-24      89.46  89.69  89.78  89.38  89.46   17626000\n",
       "2019-12-26      93.44  90.05  93.52  89.97  93.44  120108000\n",
       "2019-12-27      93.49  94.15  95.07  93.30  93.49  123732000\n",
       "2019-12-30      92.34  93.70  94.20  92.03  92.34   73494000\n",
       "\n",
       "[1761 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMZN = yf.download('AMZN', start='2013-01-01', end='2019-12-31', progress=False)\n",
    "col = ['Adj Close', 'Open', 'High', 'Low', \"Close\", \"Volume\"]\n",
    "all_data = AMZN[['Adj Close', 'Open', 'High', 'Low', \"Close\", \"Volume\"]].round(2)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(all_data, test_size=0.2, shuffle=False)\n",
    "\n",
    "input_cols = ['Adj Close', 'Open', 'High', 'Low', \"Close\", \"Volume\"]\n",
    "output_cols = ['Adj Close']\n",
    "X_train, y_train = train_df[input_cols], train_df[output_cols]\n",
    "X_test, y_test = test_df[input_cols], test_df[output_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 24\n",
    "forecast_size = 1\n",
    "step_size = 1\n",
    "\n",
    "lstm = LSTMForecaster(\n",
    "    window_size=window_size,\n",
    "    forecast_size=forecast_size,\n",
    "    hidden_size=128,\n",
    "    num_layers=1,\n",
    "    in_features=len(input_cols),\n",
    "    out_features=len(output_cols),\n",
    "    training_args=TrainingArguments(\n",
    "        criterion=nn.MSELoss,\n",
    "        optimizer=torch.optim.Adam,\n",
    "        lr=0.003,\n",
    "        max_epochs=150,\n",
    "        batch_size=32,\n",
    "        device='cuda',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m47.7532\u001b[0m     \u001b[32m5043.0654\u001b[0m  0.2333\n",
      "      2      437.9277     \u001b[32m1368.4975\u001b[0m  0.0817\n",
      "      3      132.2384      \u001b[32m690.2832\u001b[0m  0.0750\n",
      "      4       59.9912      \u001b[32m171.4048\u001b[0m  0.0755\n",
      "      5       \u001b[36m17.5862\u001b[0m       \u001b[32m83.5046\u001b[0m  0.0750\n",
      "      6        \u001b[36m5.5051\u001b[0m       \u001b[32m74.0088\u001b[0m  0.0764\n",
      "      7        \u001b[36m3.1307\u001b[0m       79.4372  0.0740\n",
      "      8        3.6457       96.0618  0.0763\n",
      "      9        \u001b[36m2.5055\u001b[0m       89.7869  0.0750\n",
      "     10        \u001b[36m2.2876\u001b[0m       92.0399  0.0730\n",
      "     11        \u001b[36m2.1583\u001b[0m       94.5210  0.0740\n",
      "     12        \u001b[36m2.1415\u001b[0m       97.3484  0.0740\n",
      "     13        2.2015      100.0710  0.0750\n",
      "     14        2.2774      102.3051  0.0750\n",
      "     15        2.3297      104.0382  0.0740\n",
      "     16        2.3493      105.6164  0.0740\n",
      "     17        2.3537      107.3811  0.0762\n",
      "     18        2.3642      109.4292  0.0750\n",
      "     19        2.3882      111.6706  0.0757\n",
      "     20        2.4177      113.9756  0.0770\n",
      "     21        2.4397      116.2431  0.0740\n",
      "     22        2.4437      118.3812  0.0780\n",
      "     23        2.4248      120.2732  0.0750\n",
      "     24        2.3805      121.7787  0.0750\n",
      "     25        2.3097      122.7669  0.0770\n",
      "     26        2.2136      123.1747  0.0758\n",
      "     27        \u001b[36m2.0997\u001b[0m      123.0815  0.0760\n",
      "     28        \u001b[36m1.9816\u001b[0m      122.7452  0.0730\n",
      "     29        \u001b[36m1.8739\u001b[0m      122.5058  0.0750\n",
      "     30        \u001b[36m1.7862\u001b[0m      122.5451  0.0779\n",
      "     31        \u001b[36m1.7186\u001b[0m      122.7333  0.0750\n",
      "     32        \u001b[36m1.6656\u001b[0m      122.7735  0.0720\n",
      "     33        \u001b[36m1.6221\u001b[0m      122.4407  0.0730\n",
      "     34        \u001b[36m1.5850\u001b[0m      121.6612  0.0720\n",
      "     35        \u001b[36m1.5527\u001b[0m      120.4787  0.0750\n",
      "     36        \u001b[36m1.5242\u001b[0m      118.9994  0.0741\n",
      "     37        \u001b[36m1.4989\u001b[0m      117.3435  0.0730\n",
      "     38        \u001b[36m1.4763\u001b[0m      115.6104  0.0750\n",
      "     39        \u001b[36m1.4556\u001b[0m      113.8623  0.0730\n",
      "     40        \u001b[36m1.4363\u001b[0m      112.1290  0.0740\n",
      "     41        \u001b[36m1.4183\u001b[0m      110.4169  0.0740\n",
      "     42        \u001b[36m1.4016\u001b[0m      108.7199  0.0790\n",
      "     43        \u001b[36m1.3862\u001b[0m      107.0231  0.0894\n",
      "     44        \u001b[36m1.3722\u001b[0m      105.3092  0.0780\n",
      "     45        \u001b[36m1.3595\u001b[0m      103.5594  0.0790\n",
      "     46        \u001b[36m1.3481\u001b[0m      101.7570  0.0810\n",
      "     47        \u001b[36m1.3377\u001b[0m       99.8902  0.0805\n",
      "     48        \u001b[36m1.3284\u001b[0m       97.9524  0.0919\n",
      "     49        \u001b[36m1.3200\u001b[0m       95.9423  0.0909\n",
      "     50        \u001b[36m1.3125\u001b[0m       93.8635  0.0908\n",
      "     51        \u001b[36m1.3057\u001b[0m       91.7218  0.0899\n",
      "     52        \u001b[36m1.2996\u001b[0m       89.5245  0.0917\n",
      "     53        \u001b[36m1.2942\u001b[0m       87.2790  0.0928\n",
      "     54        \u001b[36m1.2892\u001b[0m       84.9917  0.0890\n",
      "     55        \u001b[36m1.2846\u001b[0m       82.6705  0.0937\n",
      "     56        \u001b[36m1.2804\u001b[0m       80.3205  0.0907\n",
      "     57        \u001b[36m1.2763\u001b[0m       77.9501  0.0882\n",
      "     58        \u001b[36m1.2724\u001b[0m       75.5678  0.0860\n",
      "     59        \u001b[36m1.2684\u001b[0m       \u001b[32m73.1859\u001b[0m  0.0900\n",
      "     60        \u001b[36m1.2642\u001b[0m       \u001b[32m70.8190\u001b[0m  0.0830\n",
      "     61        \u001b[36m1.2595\u001b[0m       \u001b[32m68.4827\u001b[0m  0.0863\n",
      "     62        \u001b[36m1.2540\u001b[0m       \u001b[32m66.1891\u001b[0m  0.0866\n",
      "     63        \u001b[36m1.2471\u001b[0m       \u001b[32m63.9441\u001b[0m  0.0866\n",
      "     64        \u001b[36m1.2384\u001b[0m       \u001b[32m61.7414\u001b[0m  0.0889\n",
      "     65        \u001b[36m1.2275\u001b[0m       \u001b[32m59.5687\u001b[0m  0.0860\n",
      "     66        \u001b[36m1.2143\u001b[0m       \u001b[32m57.4072\u001b[0m  0.0850\n",
      "     67        \u001b[36m1.1988\u001b[0m       \u001b[32m55.2420\u001b[0m  0.0910\n",
      "     68        \u001b[36m1.1812\u001b[0m       \u001b[32m53.0635\u001b[0m  0.0880\n",
      "     69        \u001b[36m1.1619\u001b[0m       \u001b[32m50.8715\u001b[0m  0.0880\n",
      "     70        \u001b[36m1.1412\u001b[0m       \u001b[32m48.6712\u001b[0m  0.0890\n",
      "     71        \u001b[36m1.1196\u001b[0m       \u001b[32m46.4752\u001b[0m  0.0900\n",
      "     72        \u001b[36m1.0972\u001b[0m       \u001b[32m44.3005\u001b[0m  0.0849\n",
      "     73        \u001b[36m1.0743\u001b[0m       \u001b[32m42.1686\u001b[0m  0.0887\n",
      "     74        \u001b[36m1.0512\u001b[0m       \u001b[32m40.1013\u001b[0m  0.0870\n",
      "     75        \u001b[36m1.0281\u001b[0m       \u001b[32m38.1234\u001b[0m  0.0858\n",
      "     76        \u001b[36m1.0054\u001b[0m       \u001b[32m36.2576\u001b[0m  0.0870\n",
      "     77        \u001b[36m0.9835\u001b[0m       \u001b[32m34.5255\u001b[0m  0.0840\n",
      "     78        \u001b[36m0.9627\u001b[0m       \u001b[32m32.9432\u001b[0m  0.0886\n",
      "     79        \u001b[36m0.9432\u001b[0m       \u001b[32m31.5259\u001b[0m  0.0870\n",
      "     80        \u001b[36m0.9247\u001b[0m       \u001b[32m30.2720\u001b[0m  0.0829\n",
      "     81        \u001b[36m0.9069\u001b[0m       \u001b[32m29.1786\u001b[0m  0.0850\n",
      "     82        \u001b[36m0.8893\u001b[0m       \u001b[32m28.2277\u001b[0m  0.0874\n",
      "     83        \u001b[36m0.8715\u001b[0m       \u001b[32m27.4072\u001b[0m  0.0860\n",
      "     84        \u001b[36m0.8540\u001b[0m       \u001b[32m26.7063\u001b[0m  0.0865\n",
      "     85        \u001b[36m0.8358\u001b[0m       \u001b[32m26.1176\u001b[0m  0.0930\n",
      "     86        \u001b[36m0.8185\u001b[0m       \u001b[32m25.6382\u001b[0m  0.0870\n",
      "     87        \u001b[36m0.8021\u001b[0m       \u001b[32m25.2848\u001b[0m  0.0870\n",
      "     88        \u001b[36m0.7854\u001b[0m       \u001b[32m25.0203\u001b[0m  0.0841\n",
      "     89        \u001b[36m0.7740\u001b[0m       \u001b[32m24.9259\u001b[0m  0.0869\n",
      "     90        \u001b[36m0.7587\u001b[0m       \u001b[32m24.8788\u001b[0m  0.0880\n",
      "     91        \u001b[36m0.7522\u001b[0m       25.0444  0.0880\n",
      "     92        \u001b[36m0.7418\u001b[0m       25.2489  0.0897\n",
      "     93        \u001b[36m0.7321\u001b[0m       25.5483  0.0890\n",
      "     94        0.7375       26.2296  0.0870\n",
      "     95        \u001b[36m0.7144\u001b[0m       26.0836  0.0900\n",
      "     96        \u001b[36m0.6994\u001b[0m       27.1574  0.0882\n",
      "     97        0.7593       28.8804  0.0947\n",
      "     98        0.7344       28.3414  0.0899\n",
      "     99        0.7074       30.0702  0.0920\n",
      "    100        1.1113       30.9625  0.0920\n",
      "    101        0.7413       29.4260  0.0960\n",
      "    102        1.6539       31.8749  0.0930\n",
      "    103        1.1680       28.4583  0.0990\n",
      "    104        1.8672       27.0844  0.0930\n",
      "    105        1.0563       29.5111  0.0918\n",
      "    106        1.6045       \u001b[32m22.4957\u001b[0m  0.0944\n",
      "    107        1.1929       31.2592  0.0941\n",
      "    108        1.7572       \u001b[32m18.9104\u001b[0m  0.0954\n",
      "    109        1.2795       33.1407  0.0900\n",
      "    110        1.5960       \u001b[32m17.1638\u001b[0m  0.0962\n",
      "    111        0.9877       30.0988  0.0940\n",
      "    112        1.1426       17.5356  0.0943\n",
      "    113        0.8330       26.3446  0.0918\n",
      "    114        0.9559       17.3468  0.0910\n",
      "    115        0.8980       24.7840  0.0915\n",
      "    116        1.0746       \u001b[32m16.0927\u001b[0m  0.0910\n",
      "    117        1.1370       25.4596  0.0926\n",
      "    118        1.3630       \u001b[32m13.7427\u001b[0m  0.0920\n",
      "    119        1.2916       27.0471  0.0879\n",
      "    120        1.3372       \u001b[32m12.1971\u001b[0m  0.0880\n",
      "    121        0.9759       23.8591  0.0885\n",
      "    122        0.9488       12.6969  0.0861\n",
      "    123        0.7792       19.9914  0.0896\n",
      "    124        0.7875       12.6700  0.0890\n",
      "    125        0.8010       18.3304  0.0880\n",
      "    126        0.8690       \u001b[32m11.7486\u001b[0m  0.0902\n",
      "    127        0.9775       18.4244  0.0859\n",
      "    128        1.1283       \u001b[32m10.1088\u001b[0m  0.0894\n",
      "    129        1.2096       20.0111  0.0868\n",
      "    130        1.2847        \u001b[32m8.6100\u001b[0m  0.1131\n",
      "    131        1.0794       19.4754  0.0969\n",
      "    132        1.0234        8.6735  0.0960\n",
      "    133        0.8013       16.2225  0.0915\n",
      "    134        0.7885        9.0622  0.0905\n",
      "    135        0.7371       14.3845  0.0965\n",
      "    136        0.7830        8.8605  0.0885\n",
      "    137        0.8075       14.0153  0.0940\n",
      "    138        0.9508        \u001b[32m8.1533\u001b[0m  0.0920\n",
      "    139        0.9822       14.9105  0.0945\n",
      "    140        1.1976        \u001b[32m7.0654\u001b[0m  0.0965\n",
      "    141        1.0785       16.1059  0.0950\n",
      "    142        1.2235        \u001b[32m6.4977\u001b[0m  0.0961\n",
      "    143        0.8925       15.0895  0.0960\n",
      "    144        0.9797        6.8112  0.0930\n",
      "    145        0.7160       13.1044  0.0950\n",
      "    146        0.8448        7.1980  0.0950\n",
      "    147        \u001b[36m0.6875\u001b[0m       12.3142  0.0920\n",
      "    148        0.9041        7.2276  0.0949\n",
      "    149        0.7486       12.5764  0.0913\n",
      "    150        1.0917        6.8591  0.0960\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;slding&#x27;, SlidingWindowTransformer(window_size=24)),\n",
       "                (&#x27;lstm&#x27;,\n",
       "                 &lt;class &#x27;models.lstm.LSTMForecaster&#x27;&gt;[initialized](\n",
       "  module_=LSTM(\n",
       "    (lstm): LSTM(6, 128, batch_first=True)\n",
       "    (fc): Linear(in_features=3072, out_features=1, bias=True)\n",
       "  ),\n",
       "))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;slding&#x27;, SlidingWindowTransformer(window_size=24)),\n",
       "                (&#x27;lstm&#x27;,\n",
       "                 &lt;class &#x27;models.lstm.LSTMForecaster&#x27;&gt;[initialized](\n",
       "  module_=LSTM(\n",
       "    (lstm): LSTM(6, 128, batch_first=True)\n",
       "    (fc): Linear(in_features=3072, out_features=1, bias=True)\n",
       "  ),\n",
       "))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SlidingWindowTransformer</label><div class=\"sk-toggleable__content\"><pre>SlidingWindowTransformer(window_size=24)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LSTMForecaster</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;models.lstm.LSTMForecaster&#x27;&gt;[initialized](\n",
       "  module_=LSTM(\n",
       "    (lstm): LSTM(6, 128, batch_first=True)\n",
       "    (fc): Linear(in_features=3072, out_features=1, bias=True)\n",
       "  ),\n",
       ")</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('slding', SlidingWindowTransformer(window_size=24)),\n",
       "                ('lstm',\n",
       "                 <class 'models.lstm.LSTMForecaster'>[initialized](\n",
       "  module_=LSTM(\n",
       "    (lstm): LSTM(6, 128, batch_first=True)\n",
       "    (fc): Linear(in_features=3072, out_features=1, bias=True)\n",
       "  ),\n",
       "))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('slding', SlidingWindowTransformer(window_size=window_size, forecast_size=forecast_size, step_size=step_size)),\n",
    "        ('lstm', lstm)\n",
    "    ]\n",
    ")\n",
    "model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X=X_test)\n",
    "_, y_true = model['slding'].transform(X=None, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.919762\n"
     ]
    }
   ],
   "source": [
    "mse_list = [mean_squared_error(true, pred) for true, pred in zip(y_true, y_pred)]\n",
    "average_mse = np.mean(mse_list)\n",
    "\n",
    "print(average_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mingu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
